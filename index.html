<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 5.6.0"/><style data-href="/styles.1e8ffce35508b4661622.css" data-identity="gatsby-global-css">body{margin:0}.frame header{background-color:#af2125;border-bottom:40px;border-bottom-color:#910307;border-bottom-style:inset;font-size:xx-large;margin:0 auto;min-height:80px}.frame header .header{align-items:center;display:flex;justify-content:space-evenly;margin:0 auto;width:1000px}.frame header .header h1{margin:0 30px}.frame header .header nav a{margin:auto 20px}.frame header .header nav a,.frame header .header nav a:active,.frame header .header nav a:focus,.frame header .header nav a:hover,.frame header .header nav a:link,.frame header .header nav a:visited{color:#000;font-size:33px;font-weight:800;text-decoration:none}.frame main{margin:10px auto;max-width:1024px;padding:0 2px}.frame footer{background-color:#c7cbf2;margin:0;text-align:center}.frame footer p{margin:4px 0}.frame footer .gray{color:gray}.box{border-color:#ccc;border-radius:2px;border-style:solid;font-family:-apple-system,Noto Sans,Helvetica Neue,Helvetica,Nimbus Sans L,Arial,Liberation Sans,PingFang SC,Hiragino Sans GB,Noto Sans CJK SC,Source Han Sans SC,Source Han Sans CN,Microsoft YaHei,Wenquanyi Micro Hei,WenQuanYi Zen Hei,ST Heiti,SimHei,WenQuanYi Zen Hei Sharp,sans-serif;margin:1em 5px}.box .box-title{background-color:#ccc;font-weight:600;padding:6px}.box .box-contents{border-style:none;margin:.5em 1em}.box p{margin:initial;text-indent:2em}.intro .title{color:#036;text-align:center}.intro .title p{text-indent:0}.intro .title .cn{font-size:32px}.intro .title .en{font-size:20px}.intro .content .highlight1{color:#03c;font-size:18px}.enroll{color:#e74c3c;font-family:Verdana,Geneva,sans-serif;font-size:16px;line-height:30px}.news{margin-left:auto;margin-right:auto}.news .news-item{background:#fff;border-radius:10px;box-shadow:0 4px 4px rgba(0,0,0,.25);box-sizing:border-box;display:inline-block;margin:5px 9px;min-height:40px;opacity:1;overflow:hidden;position:relative;width:950px}.news .news-item .news-year{top:4px;width:36px}.news .news-item .news-date,.news .news-item .news-year{color:#000;font-size:13px;font-style:normal;font-weight:400;left:7px;line-height:15px;position:absolute;text-align:right}.news .news-item .news-date{top:20px;width:35px}.news .news-item .news-content{color:#000;display:block;font-size:14px;font-style:normal;font-weight:400;line-height:16px;margin:4px auto;max-width:830px;padding-left:50px}.blank{display:block;margin-top:30px}.teachers{margin-left:auto;margin-right:auto}.teachers .teacher-item{background:#fff;border-radius:20px;box-shadow:0 4px 4px rgba(0,0,0,.25);box-sizing:border-box;display:block;height:286px;margin:30px auto;position:relative;width:800px}.teachers .teacher-item .avatar{border-radius:15px;box-sizing:border-box;filter:drop-shadow(0 4px 4px rgba(0,0,0,.25));height:265px;left:11px;position:absolute;top:11px;width:216px}.teachers .teacher-item .name{top:23px}.teachers .teacher-item .name,.teachers .teacher-item .title{color:#000;font-size:18px;height:21px;left:256px;line-height:21px;position:absolute}.teachers .teacher-item .title{top:57px}.teachers .teacher-item .institution{top:91px}.teachers .teacher-item .institution,.teachers .teacher-item .researching{color:#000;font-size:18px;height:21px;left:256px;line-height:21px;position:absolute}.teachers .teacher-item .researching{top:125px}.teachers .teacher-item .website{bottom:77px}.teachers .teacher-item .email,.teachers .teacher-item .website{color:#000;font-size:18px;height:21px;left:256px;line-height:21px;position:absolute}.teachers .teacher-item .email{bottom:47px}.teachers .teacher-item .location{bottom:17px;color:#000;font-size:18px;height:21px;left:256px;line-height:21px;position:absolute}.doctors{width:987px}.doctors,.doctors .year{display:block;margin-left:auto;margin-right:auto}.doctors .year{background-color:#ddefff;border-radius:5px;font-size:larger;font-weight:bolder;padding-left:20px;width:969px}.doctors .stu-item{background:#fff;border:1px solid #000;border-radius:20px;box-sizing:border-box;display:inline-block;height:112px;margin:5px 9px;position:relative;width:311px}.doctors .stu-item,.doctors .stu-item .avatar{box-shadow:0 4px 4px rgba(0,0,0,.25);opacity:1;overflow:hidden}.doctors .stu-item .avatar{border:1px solid #000;border-bottom-left-radius:15px;border-bottom-right-radius:15px;border-top-left-radius:15px;border-top-right-radius:15px;height:87px;left:8px;position:absolute;top:10px;width:74px}.doctors .stu-item .name{left:90px}.doctors .stu-item .email,.doctors .stu-item .name{color:#000;font-size:14px;height:16px;opacity:1;position:absolute;text-align:left;top:15px}.doctors .stu-item .email{left:140px}.doctors .stu-item .location{left:90px;top:31px}.doctors .stu-item .location,.doctors .stu-item .website{color:#000;font-size:14px;height:16px;opacity:1;position:absolute;text-align:left}.doctors .stu-item .website{left:91px;top:45px}.doctors .stu-item .researching{color:#000;font-size:12px;left:91px;opacity:1;position:absolute;text-align:left;top:71px;width:207px}</style><link rel="icon" href="/favicon-32x32.png?v=3c06848e7fec85abde48b9e636ac4bad" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=3c06848e7fec85abde48b9e636ac4bad"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=3c06848e7fec85abde48b9e636ac4bad"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=3c06848e7fec85abde48b9e636ac4bad"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=3c06848e7fec85abde48b9e636ac4bad"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=3c06848e7fec85abde48b9e636ac4bad"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=3c06848e7fec85abde48b9e636ac4bad"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=3c06848e7fec85abde48b9e636ac4bad"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=3c06848e7fec85abde48b9e636ac4bad"/><title data-gatsby-head="true">XDU - ETVP</title></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="frame"><header><div class="header"><h1> XDU-ETVP </h1><nav><a aria-current="page" class="" href="/"> 首页 </a><a href="/team/"> 团队 </a></nav></div></header><main><div class="box"><div class="box-title"> <!-- -->简介<!-- --> </div><div class="box-contents"><div class="intro"><p> </p><div class="title"><p class="cn"><strong>西安电子科技大学嵌入式技术与视觉处理研究中心</strong></p><p class="en"><strong>Embedded Technology and Visual Processing Research Center, Xidian Univ.</strong></p></div><div class="content"><p>西安电子科技大学嵌入式技术与视觉处理研究中心（XDU-ETVP），成立于2015年10月。研究中心依托于原西电软件学院大数据技术和嵌入式系统实验室基础成立，重点关注深度学习技术、人机自然交互技术、机器人复杂场景中环境感知与场景理解、深度网络可解释性等热点研究方向。<span class="highlight1"> <strong>研究中心目前教授副教授6人、兼职教授5人，具有博士硕士研究生50余人，同国内外知名研究机构帝国理工大学、慕尼黑工业大学、UCLA、清华大学、北京大学、国防科技大学、浙江大学等形成了深入的合作关系。团队已经毕业研究生120余名，主要在各大互联网企业及国家重点研究机构，多名同学赴国内外知名研究机构进行博士深造。</strong></span></p></div></div></div></div><div class="box"><div class="box-title"> <!-- -->实验室招生信息<!-- --> </div><div class="box-contents"><div class="enroll"><p><big><strong><u>实验室2023年硕士研究生保研已经开始，欢迎希望致力于深度学习、人机交互、场景感知理解等技术的同学咨询（团队每年硕士研究生名额15名左右，保研名额6-10名；博士研究生名额2-3名）。</u>导师联系方式：liangzhang@xidian.edu.cn, 13700227912</strong></big></p></div></div></div><div class="box"><div class="box-title"> <!-- -->实验室新闻<!-- --> </div><div class="box-contents"><div><div class="news"><div class="news-item"><div class="news-year"> <!-- -->2016<!-- --> </div><div class="news-date"> <!-- -->12月<!-- --> </div><div class="news-content"><div> 【置顶】实验室获得西安电子科技大学首届“三好三有”导学团队荣誉称号（全校仅6支）。</div></div></div><div class="news-item"><div class="news-year"> <!-- -->2022<!-- --> </div><div class="news-date"> <!-- --> </div><div class="news-content"><div style="color:red"> 感谢实验室朱光明等老师协助，《基于多模态数据的行为和手势识别》专著已出版 </div></div></div><div class="news-item"><div class="news-year"> <!-- -->2022<!-- --> </div><div class="news-date"> <!-- --> </div><div class="news-content"><div style="color:red">恭喜实验室多名老师荣获陕西省科技进步二等奖！！！</div></div></div><div class="news-item"><div class="news-year"> <!-- -->2022<!-- --> </div><div class="news-date"> <!-- -->03-06<!-- --> </div><div class="news-content"><div style="color:red"> 恭喜实验室团队论文“Learning from Pixel-Level Label Noise: A New Perspective for Light Field Salient Object Detection”被CVPR 2022接收。 </div></div></div><div class="news-item"><div class="news-year"> <!-- -->2021<!-- --> </div><div class="news-date"> <!-- -->07-20<!-- --> </div><div class="news-content">恭喜实验室团队论文Spatio-Temporal Interaction Graph Parsing Networks for Human-Object Interaction Recognition和Free-form Description Guided 3D Visual Graph Network for Object Grounding in Point Cloud分别被顶级会议ACMMM 2021和ICCV 2021接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2021<!-- --> </div><div class="news-date"> <!-- -->06-10<!-- --> </div><div class="news-content">恭喜实验室论文Multi-Modal Co-Learning for Liver Lesion Segmentation on PET-CT Images被顶级SCI期刊IEEE Transactions on Medical Imaging录用接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2021<!-- --> </div><div class="news-date"> <!-- -->03-31<!-- --> </div><div class="news-content">欢迎大家投稿SCI期刊Sensors(IF=3.275）上面的 Special Issue “3D Object and Scene Detection, Reconstruction, Segmentation Based on Advanced Sensing Technology” ，链接地址https://www.mdpi.com/journal/sensors/special_issues/3D_Object_Scene#published</div></div><div class="news-item"><div class="news-year"> <!-- -->2021<!-- --> </div><div class="news-date"> <!-- -->03-25<!-- --> </div><div class="news-content">恭喜实验室论文“U-net based analysis of MRI for Alzheimer&#x27;s disease diagnosis”被SCI知名期刊Neural Computing and Applications（中科院2区，IF=4.774）接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2020<!-- --> </div><div class="news-date"> <!-- -->10-08<!-- --> </div><div class="news-content">恭喜实验室论文“Relation Graph Network for 3D Object Detection in Point Clouds”被顶级期刊IEEE Transactions on Image Processing（中科院I区，IF=9.34）接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2020<!-- --> </div><div class="news-date"> <!-- -->05-30<!-- --> </div><div class="news-content">恭喜实验室论文“ Analysis and Variants of Broad Learning System”被顶级期刊IEEE Transactions on Systems, Man, and Cybernetics: Systems（中科院I区，IF=7.351）接收。</div></div><details class="news-root"><summary> 显示更多新闻 </summary><div class="news-item"><div class="news-year"> <!-- -->2020<!-- --> </div><div class="news-date"> <!-- -->05-31<!-- --> </div><div class="news-content">恭喜实验室论文“Point Attention Network for Semantic Segmentation of 3D Point Clouds”被顶级国际期刊Pattern Recognition(PR，中科院I区，IF=5.898)接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2020<!-- --> </div><div class="news-date"> <!-- -->05-04<!-- --> </div><div class="news-content">恭喜实验室论文“Topology-learnable Graph Convolution for Skeleton-based Action Recognition”被知名国际期刊Pattern Recognition Letters (PRL)接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2020<!-- --> </div><div class="news-date"> <!-- -->02-14<!-- --> </div><div class="news-content">恭喜实验室2018级张家铭同学的论文《Block Level Skip Connections across Cascaded V-Net for Multi-organ Segmentation》被IEEE Transactions on Medical Imaging（TMI，中科院1区，IF=7.816，医工领域顶级期刊）期刊接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2020<!-- --> </div><div class="news-date"> <!-- -->01-24<!-- --> </div><div class="news-content">恭喜实验室论文《EFFICIENT SCENE TEXT DETECTION WITH TEXTUAL ATTENTION TOWER》被ICASSP（CCF B类）会议接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2020<!-- --> </div><div class="news-date"> <!-- -->01-11<!-- --> </div><div class="news-content">恭喜实验室2018级王旭东同学的论文《Structure-Feature based Graph Self-adaptive Pooling》被WWW(World Wide Web Conference, CCF A类)大会接收（oral presentation）。</div></div><div class="news-item"><div class="news-year"> <!-- -->2019<!-- --> </div><div class="news-date"> <!-- -->11-27<!-- --> </div><div class="news-content">祝贺实验室论文《基于扫地机器人增强位姿融合的cartographer 算法及系统实现》和《轻量级神经网络架构综述》被中文科技期刊“软件学报”（CCF A类）录用。</div></div><div class="news-item"><div class="news-year"> <!-- -->2019<!-- --> </div><div class="news-date"> <!-- -->09-23<!-- --> </div><div class="news-content">恭喜实验室杨露同学获得“国家奖学金”奖励。</div></div><div class="news-item"><div class="news-year"> <!-- -->2019<!-- --> </div><div class="news-date"> <!-- -->09-22<!-- --> </div><div class="news-content">实验室同学（2017届硕士生张美丽）参加ICIP 2019国际会议（台湾台北），并发表题为“Recoloring Image For Color Vision Deficiency By GANS”的学术报告。</div></div><div class="news-item"><div class="news-year"> <!-- -->2019<!-- --> </div><div class="news-date"> <!-- -->06-10<!-- --> </div><div class="news-content">张亮老师团队受邀参加在加拿大渥太华召开的ACM ICMR国际会议。</div></div><div class="news-item"><div class="news-year"> <!-- -->2019<!-- --> </div><div class="news-date"> <!-- -->05-24<!-- --> </div><div class="news-content">恭贺实验室手势识别论文《Redundancy and Attention in Convolutional LSTM for Gesture Recognition》被顶级期刊(Top) IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS (IEEE TNNLS，中科院1区，IF=11.683) 接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2019<!-- --> </div><div class="news-date"> <!-- -->05-01<!-- --> </div><div class="news-content">恭喜实验室2017级张美丽同学的论文,《Recoloring Image for Color Vision Deficiency by GANs》被ICIP 2019大会接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2019<!-- --> </div><div class="news-date"> <!-- -->04-01<!-- --> </div><div class="news-content">恭喜实验室论文《Relationship Detection Based on Object Semantic Inference and Attention Mechanisms》被ICMR 2019( International Conference on Multimedia Retrieval, CCF B类)接收。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->10-19<!-- --> </div><div class="news-content">恭喜实验室孔祥雯和汪乐两位同学获得“国家奖学金”奖励。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->09-19<!-- --> </div><div class="news-content">实验室机器人SLAM论文 《Semantic SLAM based on Object Detection and Improved Octomap》被SCI期刊IEEE ACCESS (IF=3.557)录用。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->09-05<!-- --> </div><div class="news-content">恭贺实验室论文 《Attention in Convolutional LSTM for Gesture Recognition》被顶级国际会议2018NIPS(神经信息处理系统大会) 录用。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->9月<!-- --> </div><div class="news-content">实验室室内场景分割论文 《Semantic Scene Completion with Dense CRF from a Single Depth Image》被顶级SCI期刊 Neurocomputing (IF=3.241) 录用。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->8月<!-- --> </div><div class="news-content">实验室申请的发明专利“一种利用多核DSP实现动态任务调度分发的方法”被授权。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->8月<!-- --> </div><div class="news-content">实验室孔祥雯同学代表实验室参加第24届国际模式识别大会ICPR。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->7月<!-- --> </div><div class="news-content">实验室基于深度学习的手势识别论文 《Continuous Gesture Segmentation and Recognition using 3DCNN and Convolutional LSTM》被顶级SCI期刊 IEEE Transactions on Multimedia (IF=3.977) 录用。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->7月<!-- --> </div><div class="news-content">实验室四个发明专利被授权，分别是：“一种基于OpenCL的图像去噪算法的并行优化方法（ZL201510400551.1）”、“一种眼睛、嘴巴及多关节可动提线木偶(ZL201510664917.6)”、“一种智能提线木偶偶人控制系统(ZL201510665239.5）”、“一种智能提线木偶偶人控制方法（ZL201510665784.4）”。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->06-05<!-- --> </div><div class="news-content">实验室项目《嵌入式智能视觉传感器》参加2018年中国国际自动化与机器人展览会（IARS）。实验室学生马洁，田阳，朱姚姚，张丰等四位同学赴武汉国际博览中心参展。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->06-01<!-- --> </div><div class="news-content">实验室2015级研究生李欢，魏乐麒，张笑，张淑娥，刘欢等五位同学顺利通过硕士毕业论文答辩。答辩委员会同意授予5位同学工学硕士学位。</div></div><div class="news-item"><div class="news-year"> <!-- -->2018<!-- --> </div><div class="news-date"> <!-- -->05-24<!-- --> </div><div class="news-content">实验室2017级孔祥雯同学的论文《Reflective Field for Pixel-Level Tasks》被 ICPR 2018 大会录取，延续着实验室每年在该国际会议上录取的传统。</div></div></details></div></div></div></div></main><footer><p> 嵌入式技术与视觉处理研究中心 </p><p> 西安电子科技大学 </p><p class="gray"> 陕西省西安市太白南路2号 </p><p class="gray"> Copyright (C) <!-- -->2023<!-- --> </p></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/";/*]]>*/</script><!-- slice-start id="_gatsby-scripts-1" -->
          <script
            id="gatsby-chunk-mapping"
          >
            window.___chunkMapping="{\"app\":[\"/app-e2a5780d27f2ac2634e0.js\"],\"component---src-pages-404-tsx\":[\"/component---src-pages-404-tsx-b79f74c22a510c3a1c80.js\"],\"component---src-pages-index-tsx\":[\"/component---src-pages-index-tsx-d2df9a0b52baac8258b6.js\"],\"component---src-pages-team-index-tsx\":[\"/component---src-pages-team-index-tsx-47d11f397a14267cb7dc.js\"]}";
          </script>
        <script>window.___webpackCompilationHash="c4311c7f83e37f5e9d7d";</script><script src="/webpack-runtime-0ef9d3d76d3b4ee4799a.js" async></script><script src="/framework-96718d25fb66714d6b55.js" async></script><script src="/app-e2a5780d27f2ac2634e0.js" async></script><!-- slice-end id="_gatsby-scripts-1" --></body></html>